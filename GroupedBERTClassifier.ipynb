{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:42:34.868026Z",
          "iopub.status.busy": "2022-12-13T02:42:34.867370Z",
          "iopub.status.idle": "2022-12-13T02:42:43.579576Z",
          "shell.execute_reply": "2022-12-13T02:42:43.578624Z",
          "shell.execute_reply.started": "2022-12-13T02:42:34.868002Z"
        },
        "id": "NIJGTIRqwShE"
      },
      "outputs": [],
      "source": [
        "!python -m pip install transformers torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngWuYXW8gTbz"
      },
      "outputs": [],
      "source": [
        "# !python -m pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:42:57.757024Z",
          "iopub.status.busy": "2022-12-13T02:42:57.756521Z",
          "iopub.status.idle": "2022-12-13T02:42:57.760519Z",
          "shell.execute_reply": "2022-12-13T02:42:57.759853Z",
          "shell.execute_reply.started": "2022-12-13T02:42:57.756997Z"
        },
        "id": "oXiusUlFgdIi",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:43:11.709089Z",
          "iopub.status.busy": "2022-12-13T02:43:11.708688Z",
          "iopub.status.idle": "2022-12-13T02:43:11.712531Z",
          "shell.execute_reply": "2022-12-13T02:43:11.711771Z",
          "shell.execute_reply.started": "2022-12-13T02:43:11.709063Z"
        },
        "id": "w_pbAVyEgTb2"
      },
      "outputs": [],
      "source": [
        "import transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:43:13.776955Z",
          "iopub.status.busy": "2022-12-13T02:43:13.776546Z",
          "iopub.status.idle": "2022-12-13T02:43:15.129195Z",
          "shell.execute_reply": "2022-12-13T02:43:15.128459Z",
          "shell.execute_reply.started": "2022-12-13T02:43:13.776929Z"
        },
        "id": "7SvCi2JuhC5P"
      },
      "outputs": [],
      "source": [
        "import traceback\n",
        "import csv\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def write_tsv_dataframe(filepath, dataframe):\n",
        "    \"\"\"\n",
        "        Stores `DataFrame` as tsv file\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        filepath : str\n",
        "            Path to tsv file\n",
        "        dataframe : pd.DataFrame\n",
        "            DataFrame to store\n",
        "\n",
        "        Raises\n",
        "        ------\n",
        "        IOError\n",
        "            if the file can't be opened\n",
        "    \"\"\"\n",
        "    try:\n",
        "        dataframe.to_csv(filepath, encoding='utf-8', sep='\\t', index=False, header=True, quoting=csv.QUOTE_NONE)\n",
        "    except IOError:\n",
        "        traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:43:58.549399Z",
          "iopub.status.busy": "2022-12-13T02:43:58.548907Z",
          "iopub.status.idle": "2022-12-13T02:43:58.553163Z",
          "shell.execute_reply": "2022-12-13T02:43:58.552471Z",
          "shell.execute_reply.started": "2022-12-13T02:43:58.549373Z"
        },
        "id": "Ve5zjHvhhIMT"
      },
      "outputs": [],
      "source": [
        "def combine_columns(df_arguments, df_labels):\n",
        "    \"\"\"Combines the two `DataFrames` on column `Argument ID`\"\"\"\n",
        "    return pd.merge(df_arguments, df_labels, on='Argument ID')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:44:00.763898Z",
          "iopub.status.busy": "2022-12-13T02:44:00.763518Z",
          "iopub.status.idle": "2022-12-13T02:44:00.768856Z",
          "shell.execute_reply": "2022-12-13T02:44:00.768108Z",
          "shell.execute_reply.started": "2022-12-13T02:44:00.763871Z"
        },
        "id": "tnaaQHrnhYnh"
      },
      "outputs": [],
      "source": [
        "def split_arguments(df_arguments):\n",
        "    \"\"\"Splits `DataFrame` by column `Usage` into `train`-, `validation`-, and `test`-arguments\"\"\"\n",
        "    train_arguments = df_arguments.loc[df_arguments['Usage'] == 'train'].drop(['Usage'], axis=1).reset_index(drop=True)\n",
        "    valid_arguments = df_arguments.loc[df_arguments['Usage'] == 'validation'].drop(['Usage'], axis=1).reset_index(drop=True)\n",
        "    test_arguments = df_arguments.loc[df_arguments['Usage'] == 'test'].drop(['Usage'], axis=1).reset_index(drop=True)\n",
        "    \n",
        "    return train_arguments, valid_arguments, test_arguments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:44:02.019019Z",
          "iopub.status.busy": "2022-12-13T02:44:02.018624Z",
          "iopub.status.idle": "2022-12-13T02:44:02.023586Z",
          "shell.execute_reply": "2022-12-13T02:44:02.022692Z",
          "shell.execute_reply.started": "2022-12-13T02:44:02.018995Z"
        },
        "id": "kpljNrsChbf1"
      },
      "outputs": [],
      "source": [
        "def create_dataframe_head(argument_ids, model_name):\n",
        "    \"\"\"\n",
        "        Creates `DataFrame` usable to append predictions to it\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        argument_ids : list[str]\n",
        "            First column of the resulting DataFrame\n",
        "        model_name : str\n",
        "            Second column of DataFrame will contain the given model name\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pd.DataFrame\n",
        "            prepared DataFrame\n",
        "    \"\"\"\n",
        "    df_model_head = pd.DataFrame(argument_ids, columns=['Argument ID'])\n",
        "    df_model_head['Method'] = [model_name] * len(argument_ids)\n",
        "\n",
        "    return df_model_head\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:44:02.855102Z",
          "iopub.status.busy": "2022-12-13T02:44:02.854709Z",
          "iopub.status.idle": "2022-12-13T02:44:02.858640Z",
          "shell.execute_reply": "2022-12-13T02:44:02.857972Z",
          "shell.execute_reply.started": "2022-12-13T02:44:02.855079Z"
        },
        "id": "1MgX3B55hd9P"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "class MissingColumnError(AttributeError):\n",
        "    \"\"\"Error indicating that an imported DataFrame lacks necessary columns\"\"\"\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:44:03.596045Z",
          "iopub.status.busy": "2022-12-13T02:44:03.595659Z",
          "iopub.status.idle": "2022-12-13T02:44:03.599702Z",
          "shell.execute_reply": "2022-12-13T02:44:03.599035Z",
          "shell.execute_reply.started": "2022-12-13T02:44:03.596020Z"
        },
        "id": "Qe-7L7j3ho_X"
      },
      "outputs": [],
      "source": [
        "def load_json_file(filepath):\n",
        "    \"\"\"Load content of json-file from `filepath`\"\"\"\n",
        "    with open(filepath, 'r') as  json_file:\n",
        "        return json.load(json_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:44:04.497082Z",
          "iopub.status.busy": "2022-12-13T02:44:04.496266Z",
          "iopub.status.idle": "2022-12-13T02:44:04.503370Z",
          "shell.execute_reply": "2022-12-13T02:44:04.502403Z",
          "shell.execute_reply.started": "2022-12-13T02:44:04.497050Z"
        },
        "id": "vWGzjs9lhq_s"
      },
      "outputs": [],
      "source": [
        "def load_values_from_json(filepath):\n",
        "    \"\"\"Load values per level from json-file from `filepath`\"\"\"\n",
        "    json_values = load_json_file(filepath)\n",
        "    values = { \"1\":set(), \"2\":set(), \"3\":set(), \"4a\":set(), \"4b\":set() }\n",
        "    for value in json_values[\"values\"]:\n",
        "        values[\"1\"].add(value[\"name\"])\n",
        "        values[\"2\"].add(value[\"level2\"])\n",
        "        for valueLevel3 in value[\"level3\"]:\n",
        "            values[\"3\"].add(valueLevel3)\n",
        "        for valueLevel4a in value[\"level4a\"]:\n",
        "            values[\"4a\"].add(valueLevel4a)\n",
        "        for valueLevel4b in value[\"level4b\"]:\n",
        "            values[\"4b\"].add(valueLevel4b)\n",
        "    values[\"1\"] = sorted(values[\"1\"])\n",
        "    values[\"2\"] = sorted(values[\"2\"])\n",
        "    values[\"3\"] = sorted(values[\"3\"])\n",
        "    values[\"4a\"] = sorted(values[\"4a\"])\n",
        "    values[\"4b\"] = sorted(values[\"4b\"])\n",
        "    return values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:44:05.473120Z",
          "iopub.status.busy": "2022-12-13T02:44:05.472724Z",
          "iopub.status.idle": "2022-12-13T02:44:05.478556Z",
          "shell.execute_reply": "2022-12-13T02:44:05.477772Z",
          "shell.execute_reply.started": "2022-12-13T02:44:05.473096Z"
        },
        "id": "HpBKjzIihtk0"
      },
      "outputs": [],
      "source": [
        "def load_arguments_from_tsv(filepath, default_usage='test'):\n",
        "    \"\"\"\n",
        "        Reads arguments from tsv file\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        filepath : str\n",
        "            The path to the tsv file\n",
        "        default_usage : str, optional\n",
        "            The default value if the column \"Usage\" is missing\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pd.DataFrame\n",
        "            the DataFrame with all arguments\n",
        "\n",
        "        Raises\n",
        "        ------\n",
        "        MissingColumnError\n",
        "            if the required columns \"Argument ID\" or \"Premise\" are missing in the read data\n",
        "        IOError\n",
        "            if the file can't be read\n",
        "        \"\"\"\n",
        "    try:\n",
        "        dataframe = pd.read_csv(filepath, encoding='utf-8', sep='\\t', header=0)\n",
        "        if not {'Argument ID', 'Premise'}.issubset(set(dataframe.columns.values)):\n",
        "            raise MissingColumnError('The argument \"%s\" file does not contain the minimum required columns [Argument ID, Premise].' % filepath)\n",
        "        if 'Usage' not in dataframe.columns.values:\n",
        "            dataframe['Usage'] = [default_usage] * len(dataframe)\n",
        "        return dataframe\n",
        "    except IOError:\n",
        "        traceback.print_exc()\n",
        "        raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:44:06.949946Z",
          "iopub.status.busy": "2022-12-13T02:44:06.949560Z",
          "iopub.status.idle": "2022-12-13T02:44:06.954868Z",
          "shell.execute_reply": "2022-12-13T02:44:06.954107Z",
          "shell.execute_reply.started": "2022-12-13T02:44:06.949920Z"
        },
        "id": "lTFyn21VhwsY"
      },
      "outputs": [],
      "source": [
        "def load_labels_from_tsv(filepath, label_order):\n",
        "    \"\"\"\n",
        "        Reads label annotations from tsv file\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        filepath : str\n",
        "            The path to the tsv file\n",
        "        label_order : list[str]\n",
        "            The listing and order of the labels to use from the read data\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pd.DataFrame\n",
        "            the DataFrame with the annotations\n",
        "\n",
        "        Raises\n",
        "        ------\n",
        "        MissingColumnError\n",
        "            if the required columns \"Argument ID\" or names from `label_order` are missing in the read data\n",
        "        IOError\n",
        "            if the file can't be read\n",
        "        \"\"\"\n",
        "    try:\n",
        "        label_order = [\"Self-direction: thought\",\t\"Self-direction: action\",\t\"Stimulation\",\t\"Hedonism\",\t\"Achievement\",\t\"Power: dominance\",\t\"Power: resources\",\t\"Face\",\t\"Security: personal\",\t\"Security: societal\",\t\"Tradition\",\t\"Conformity: rules\",\t\"Conformity: interpersonal\",\t\"Humility\",\t\"Benevolence: caring\",\t\"Benevolence: dependability\",\t\"Universalism: concern\",\t\"Universalism: nature\",\t\"Universalism: tolerance\",\t\"Universalism: objectivity\"]\n",
        "        dataframe = pd.read_csv(filepath, encoding='utf-8', sep='\\t', header=0)\n",
        "        dataframe = dataframe[['Argument ID'] + label_order]\n",
        "        return dataframe\n",
        "    except IOError:\n",
        "        traceback.print_exc()\n",
        "        raise\n",
        "    except KeyError:\n",
        "        raise MissingColumnError('The file \"%s\" does not contain the required columns for its level.' % filepath)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:44:07.921136Z",
          "iopub.status.busy": "2022-12-13T02:44:07.920719Z",
          "iopub.status.idle": "2022-12-13T02:44:07.924701Z",
          "shell.execute_reply": "2022-12-13T02:44:07.923936Z",
          "shell.execute_reply.started": "2022-12-13T02:44:07.921113Z"
        },
        "id": "yxSNyT8Why1g"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import getopt\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:44:08.702694Z",
          "iopub.status.busy": "2022-12-13T02:44:08.702318Z",
          "iopub.status.idle": "2022-12-13T02:44:08.706365Z",
          "shell.execute_reply": "2022-12-13T02:44:08.705588Z",
          "shell.execute_reply.started": "2022-12-13T02:44:08.702669Z"
        },
        "id": "dQ_Eh4qMi6dA"
      },
      "outputs": [],
      "source": [
        "model_dir = 'models'\n",
        "data_dir = 'data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:44:09.630782Z",
          "iopub.status.busy": "2022-12-13T02:44:09.630085Z",
          "iopub.status.idle": "2022-12-13T02:44:09.634319Z",
          "shell.execute_reply": "2022-12-13T02:44:09.633605Z",
          "shell.execute_reply.started": "2022-12-13T02:44:09.630752Z"
        },
        "id": "HHejuM1kh4i8"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:44:45.945060Z",
          "iopub.status.busy": "2022-12-13T02:44:45.944641Z",
          "iopub.status.idle": "2022-12-13T02:44:45.948609Z",
          "shell.execute_reply": "2022-12-13T02:44:45.947866Z",
          "shell.execute_reply.started": "2022-12-13T02:44:45.945029Z"
        },
        "id": "MurNX18XjWIw"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:44:46.606739Z",
          "iopub.status.busy": "2022-12-13T02:44:46.606357Z",
          "iopub.status.idle": "2022-12-13T02:44:46.613469Z",
          "shell.execute_reply": "2022-12-13T02:44:46.612723Z",
          "shell.execute_reply.started": "2022-12-13T02:44:46.606710Z"
        },
        "id": "PY77MuApiuUW"
      },
      "outputs": [],
      "source": [
        "def generate_pairwise_input(dataset, labels, datatype):\n",
        "    \"\"\"\n",
        "    TODO: group all premises and corresponding hypotheses and labels of the datapoints\n",
        "    a datapoint as seen earlier is a dict of premis, hypothesis and label\n",
        "    \"\"\"\n",
        "    #raise NotImplementedError\n",
        "    premise=[]\n",
        "    conclusion=[]\n",
        "    stance=[]\n",
        "    n_labels =labels.keys()\n",
        "    n_labels = n_labels[1:]\n",
        "    print(n_labels)\n",
        "    label=[]\n",
        "    \n",
        "    n = len(dataset['Argument ID'])\n",
        "    m = len(labels['Argument ID'])\n",
        "    arguments = []\n",
        "    print(n,m)\n",
        "    for i in range(n):\n",
        "        if dataset['Usage'][i]==datatype:\n",
        "          premise.append(dataset['Premise'][i])\n",
        "          conclusion.append(dataset['Conclusion'][i])\n",
        "          stance.append(dataset['Stance'][i])\n",
        "          arguments.append(dataset['Argument ID'][i])\n",
        "    for i in range(m):\n",
        "        if (labels['Argument ID'][i] in arguments):\n",
        "          sent_label = []\n",
        "          #print(i)\n",
        "          for l in range(len(n_labels)):\n",
        "              #print(n_labels[l])\n",
        "              sent_label.append(int(labels[n_labels[l]][i]))\n",
        "          label.append(sent_label)\n",
        "\n",
        "    return premise, conclusion, stance, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6AANdaaoghx"
      },
      "outputs": [],
      "source": [
        "value_json_filepath = os.path.join(data_dir, 'values.json')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values = load_values_from_json(value_json_filepath)\n",
        "num_labels_Lv2 = len(values['2'])\n",
        "level =2\n"
      ],
      "metadata": {
        "id": "rW3UNtjZJ0NM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "argument_filepath = os.path.join(data_dir, 'arguments-training.tsv')\n",
        "\n",
        "df_arguments = load_arguments_from_tsv(argument_filepath, default_usage='train')\n",
        "label_filepath = os.path.join(data_dir, 'labels-training.tsv')\n",
        "df_labels = load_labels_from_tsv(label_filepath, values[str(level)])"
      ],
      "metadata": {
        "id": "ZeNaQX6-J1qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:44:49.183127Z",
          "iopub.status.busy": "2022-12-13T02:44:49.182711Z",
          "iopub.status.idle": "2022-12-13T02:44:50.188227Z",
          "shell.execute_reply": "2022-12-13T02:44:50.187496Z",
          "shell.execute_reply.started": "2022-12-13T02:44:49.183099Z"
        },
        "id": "9WvikqGWln63"
      },
      "outputs": [],
      "source": [
        "train_premises, train_conclusion, train_stance, train_labels = generate_pairwise_input(df_arguments, df_labels, 'train')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c03vedT88bWs"
      },
      "outputs": [],
      "source": [
        "len(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejPZUtOS5NSy"
      },
      "outputs": [],
      "source": [
        "val_argument_filepath = os.path.join(data_dir, 'arguments-validation.tsv')\n",
        "df_arguments_val = load_arguments_from_tsv(val_argument_filepath, default_usage='validation')\n",
        "val_label_filepath = os.path.join(data_dir, 'labels-validation.tsv')\n",
        "df_labels_val = load_labels_from_tsv(val_label_filepath, values[str(level)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giFRSkDo5biA"
      },
      "outputs": [],
      "source": [
        "val_premises, val_conclusion, val_stance, val_labels = generate_pairwise_input(df_arguments_val, df_labels_val, 'validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:45:00.917945Z",
          "iopub.status.busy": "2022-12-13T02:45:00.917556Z",
          "iopub.status.idle": "2022-12-13T02:45:01.882554Z",
          "shell.execute_reply": "2022-12-13T02:45:01.881731Z",
          "shell.execute_reply.started": "2022-12-13T02:45:00.917920Z"
        },
        "id": "XhW38nWHv2tj"
      },
      "outputs": [],
      "source": [
        "# Nothing to do for this class!\n",
        "import torch\n",
        "from transformers import BertModel\n",
        "from transformers import AutoTokenizer\n",
        "from typing import Dict, List\n",
        "\n",
        "class BatchTokenizer:\n",
        "    \"\"\"Tokenizes and pads a batch of input sentences.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initializes the tokenizer\n",
        "\n",
        "        Args:\n",
        "            pad_symbol (Optional[str], optional): The symbol for a pad. Defaults to \"<P>\".\n",
        "        \"\"\"\n",
        "        self.hf_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "    \n",
        "    def get_sep_token(self,):\n",
        "        return self.hf_tokenizer.sep_token\n",
        "    \n",
        "    def __call__(self, prem_batch: List[str], hyp_batch: List[str], stance_batch: List[str]) -> List[List[str]]:\n",
        "        \"\"\"Uses the huggingface tokenizer to tokenize and pad a batch.\n",
        "\n",
        "        We return a dictionary of tensors per the huggingface model specification.\n",
        "\n",
        "        Args:\n",
        "            batch (List[str]): A List of sentence strings\n",
        "\n",
        "        Returns:\n",
        "            Dict: The dictionary of token specifications provided by HuggingFace\n",
        "        \"\"\"\n",
        "        # The HF tokenizer will PAD for us, and additionally combine \n",
        "        # The two sentences deimited by the [SEP] token.\n",
        "        batch_len = len(prem_batch)\n",
        "        #spaces = [\" \"]*batch_len\n",
        "        conc_batch = [stance_batch[i]+\" \"+hyp_batch[i] for i in range(batch_len)]\n",
        "        enc = self.hf_tokenizer(\n",
        "            prem_batch,\n",
        "            conc_batch,\n",
        "            padding=True,\n",
        "            return_token_type_ids=False,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return enc\n",
        "    \n",
        "\n",
        "# HERE IS AN EXAMPLE OF HOW TO USE THE BATCH TOKENIZER\n",
        "tokenizer = BatchTokenizer()\n",
        "a = [[\"this is the premise.\", \"This is also a premise\"], [\"this is the hypothesis\", \"This is a second hypothesis\"],[\"in favour of\", \"against\"]]\n",
        "x = tokenizer(*a)\n",
        "print(x)\n",
        "tokenizer.hf_tokenizer.batch_decode(x[\"input_ids\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:45:14.152341Z",
          "iopub.status.busy": "2022-12-13T02:45:14.151968Z",
          "iopub.status.idle": "2022-12-13T02:45:14.159088Z",
          "shell.execute_reply": "2022-12-13T02:45:14.158245Z",
          "shell.execute_reply.started": "2022-12-13T02:45:14.152315Z"
        },
        "id": "FQWwRKXgrYRY"
      },
      "outputs": [],
      "source": [
        "def chunk(lst, n):\n",
        "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[:][i:i + n]\n",
        "\n",
        "def chunk_multi(lst1, lst2, lst3, n):\n",
        "    for i in range(0, len(lst1), n):\n",
        "        yield lst1[i: i + n], lst2[i: i + n], lst3[i: i + n]\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:45:20.743432Z",
          "iopub.status.busy": "2022-12-13T02:45:20.743021Z",
          "iopub.status.idle": "2022-12-13T02:45:20.755493Z",
          "shell.execute_reply": "2022-12-13T02:45:20.754803Z",
          "shell.execute_reply.started": "2022-12-13T02:45:20.743405Z"
        },
        "id": "tCdddSnCwwmA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:45:21.743206Z",
          "iopub.status.busy": "2022-12-13T02:45:21.742789Z",
          "iopub.status.idle": "2022-12-13T02:45:21.746522Z",
          "shell.execute_reply": "2022-12-13T02:45:21.745713Z",
          "shell.execute_reply.started": "2022-12-13T02:45:21.743179Z"
        },
        "id": "nchPyT3yAtW3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:45:29.573266Z",
          "iopub.status.busy": "2022-12-13T02:45:29.572874Z",
          "iopub.status.idle": "2022-12-13T02:45:29.996553Z",
          "shell.execute_reply": "2022-12-13T02:45:29.995852Z",
          "shell.execute_reply.started": "2022-12-13T02:45:29.573242Z"
        },
        "id": "v-COBdmXv1Gf"
      },
      "outputs": [],
      "source": [
        "# Notice that since we use huggingface, we tokenize and\n",
        "# encode in all at once!\n",
        "batch_size=64\n",
        "tokenizer = BatchTokenizer()\n",
        "train_input_batches = [b for b in chunk_multi(train_premises, train_conclusion, train_stance, batch_size)]\n",
        "# Tokenize + encode\n",
        "train_input_batches = [tokenizer(*batch) for batch in train_input_batches]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-H-JWr6-snT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:45:33.570360Z",
          "iopub.status.busy": "2022-12-13T02:45:33.569967Z",
          "iopub.status.idle": "2022-12-13T02:45:33.594567Z",
          "shell.execute_reply": "2022-12-13T02:45:33.593930Z",
          "shell.execute_reply.started": "2022-12-13T02:45:33.570333Z"
        },
        "id": "W_ta_vSAx4oz"
      },
      "outputs": [],
      "source": [
        "val_input_batches = [b for b in chunk_multi(val_premises, val_conclusion, val_stance, batch_size)]\n",
        "# Tokenize + encode\n",
        "val_input_batches = [tokenizer(*batch) for batch in val_input_batches]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:45:34.355011Z",
          "iopub.status.busy": "2022-12-13T02:45:34.354621Z",
          "iopub.status.idle": "2022-12-13T02:45:34.359633Z",
          "shell.execute_reply": "2022-12-13T02:45:34.358932Z",
          "shell.execute_reply.started": "2022-12-13T02:45:34.354986Z"
        },
        "id": "3VwgQMkk1ZxW"
      },
      "outputs": [],
      "source": [
        "len(val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:45:35.525532Z",
          "iopub.status.busy": "2022-12-13T02:45:35.525128Z",
          "iopub.status.idle": "2022-12-13T02:45:35.529805Z",
          "shell.execute_reply": "2022-12-13T02:45:35.529145Z",
          "shell.execute_reply.started": "2022-12-13T02:45:35.525507Z"
        },
        "id": "Dxc4DhACkRub"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bsKdbnIkuIm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcpr79zBlkA4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTzmh5jllbgN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1_4wLaXlff-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xF7TKu_Snw2Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3Iu_ZuV-frm"
      },
      "outputs": [],
      "source": [
        "# 0 Self-direction: thought\n",
        "# 1 Self-direction: action\t\n",
        "# 2 Stimulation\t\n",
        "# 3 Hedonism\t\n",
        "# 4 Achievement\t\n",
        "# 5 Power: dominance\t\n",
        "# 6 Power: resources\t\n",
        "# 7 Face\t\n",
        "# 8 Security: personal\t\n",
        "# 9 Security: societal\t\n",
        "# 10 Tradition\t\n",
        "# 11 Conformity: rules\t\n",
        "# 12 Conformity: interpersonal\t\n",
        "# 13 Humility\t\n",
        "# 14 Benevolence: caring\t\n",
        "# 15 Benevolence: dependability\t\n",
        "# 16 Universalism: concern\t\n",
        "# 17 Universalism: nature\t\n",
        "# 18 Universalism: tolerance\t\n",
        "# 19 Universalism: objectivity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJkxz-oO_MRQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:45:50.832297Z",
          "iopub.status.busy": "2022-12-13T02:45:50.831601Z",
          "iopub.status.idle": "2022-12-13T02:45:50.836567Z",
          "shell.execute_reply": "2022-12-13T02:45:50.835799Z",
          "shell.execute_reply.started": "2022-12-13T02:45:50.832266Z"
        },
        "id": "mU8iunXrrdbL"
      },
      "outputs": [],
      "source": [
        "# Achievement, Face, Power: dominance, Power: resources [4, 5, 6, 7]\n",
        "\n",
        "\n",
        "#Benevolence: caring, Benevolence: dependability, Humility, Universalism: concern [13,14,15, 16]\n",
        "\n",
        "\n",
        "# Stimulation, Tradition, Self-direction: action, Self-direction: thought [2, 10, 0, 1]\n",
        "\n",
        "\n",
        "# Conformity: interpersonal, Conformity: rules, Security: personal, Security: societal [11, 12, 8, 9]\n",
        "\n",
        "\n",
        "# Hedonism, Universalism: nature, Universalism: objectivity, Universalism: tolerance [3, 17,18, 19]\n",
        "# Note: This is just one possible way to group these elements. There may be other valid ways to do so.\n",
        "\n",
        "\n",
        "clusters = [\n",
        "    [4, 5, 6, 7],\n",
        "    [13,14,15, 16],\n",
        "    [2, 10, 0, 1],\n",
        "    [11, 12, 8, 9],\n",
        "    [3, 17,18, 19]\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:45:55.443494Z",
          "iopub.status.busy": "2022-12-13T02:45:55.443061Z",
          "iopub.status.idle": "2022-12-13T02:45:55.448890Z",
          "shell.execute_reply": "2022-12-13T02:45:55.448085Z",
          "shell.execute_reply.started": "2022-12-13T02:45:55.443469Z"
        },
        "id": "XgY4RO1-05Tz"
      },
      "outputs": [],
      "source": [
        "def encode_labels(labels: List[List[int]]) -> torch.FloatTensor:\n",
        "    \"\"\"Turns the batch of labels into a tensor\n",
        "        Add labels for grouped classes\n",
        "    Args:\n",
        "        labels (List[List[int]]): List of all labels in the batch\n",
        "\n",
        "    Returns:\n",
        "        torch.FloatTensor: Tensor of all labels in the batch\n",
        "    \"\"\"\n",
        "    \n",
        "    extended_labels = []\n",
        "    for i in range(len(labels)):\n",
        "      elabels = [p for p in labels[i]]\n",
        "      #Cluster 0\n",
        "      for j in range(len(clusters)):\n",
        "        clf = clusters[j]\n",
        "        l = 0\n",
        "        for k in clusters[j]:\n",
        "          if(elabels[k]==1):\n",
        "            l = 1\n",
        "            break\n",
        "        elabels.append(l)\n",
        "      extended_labels.append(elabels)\n",
        "    #print(len(extended_labels[0]), len(labels[0]))\n",
        "    return torch.LongTensor(extended_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:45:57.751567Z",
          "iopub.status.busy": "2022-12-13T02:45:57.751178Z",
          "iopub.status.idle": "2022-12-13T02:45:57.758490Z",
          "shell.execute_reply": "2022-12-13T02:45:57.757883Z",
          "shell.execute_reply.started": "2022-12-13T02:45:57.751540Z"
        },
        "id": "d8msMWSo23d1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:46:01.765826Z",
          "iopub.status.busy": "2022-12-13T02:46:01.765431Z",
          "iopub.status.idle": "2022-12-13T02:46:01.827964Z",
          "shell.execute_reply": "2022-12-13T02:46:01.827109Z",
          "shell.execute_reply.started": "2022-12-13T02:46:01.765800Z"
        },
        "id": "MVvh4bZAgTcu"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:46:06.617376Z",
          "iopub.status.busy": "2022-12-13T02:46:06.616963Z",
          "iopub.status.idle": "2022-12-13T02:46:06.633908Z",
          "shell.execute_reply": "2022-12-13T02:46:06.633047Z",
          "shell.execute_reply.started": "2022-12-13T02:46:06.617351Z"
        },
        "id": "cw7wSXAk19YY"
      },
      "outputs": [],
      "source": [
        "train_label_batches = [b for b in chunk(train_labels, batch_size)]\n",
        "train_label_batches = [encode_labels(batch) for batch in train_label_batches]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:46:08.245221Z",
          "iopub.status.busy": "2022-12-13T02:46:08.244828Z",
          "iopub.status.idle": "2022-12-13T02:46:08.250140Z",
          "shell.execute_reply": "2022-12-13T02:46:08.249278Z",
          "shell.execute_reply.started": "2022-12-13T02:46:08.245196Z"
        },
        "id": "s2Jl56Mg2HdF"
      },
      "outputs": [],
      "source": [
        "val_label_batches = [b for b in chunk(val_labels, batch_size)]\n",
        "val_label_batches = [encode_labels(batch) for batch in val_label_batches]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9i5nn1qT244"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Grouped Classifier**"
      ],
      "metadata": {
        "id": "BsZyCEwdRA5s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T06:07:41.438953Z",
          "iopub.status.busy": "2022-12-13T06:07:41.438557Z",
          "iopub.status.idle": "2022-12-13T06:07:41.695765Z",
          "shell.execute_reply": "2022-12-13T06:07:41.694828Z",
          "shell.execute_reply.started": "2022-12-13T06:07:41.438928Z"
        },
        "id": "qsgi7io72ewY",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class GroupedClassifier(torch.nn.Module):\n",
        "    def __init__(self, output_size: int, hidden_size: int):\n",
        "        super().__init__()\n",
        "        self.output_size = output_size\n",
        "        self.hidden_size = hidden_size\n",
        "        # Initialize BERT, which we use instead of a single embedding layer.\n",
        "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "        # Updating all BERT parameters can be slow and memory intensive. \n",
        "        # Freeze them if training is too slow. Notice that the learning\n",
        "        # rate should probably be smaller in this case.\n",
        "        # Uncommenting out the below 2 lines means only our classification layer will be updated.\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = True\n",
        "        self.bert_hidden_dimension = self.bert.config.hidden_size\n",
        "        print(self.bert_hidden_dimension)\n",
        "        \n",
        "        # Grouped layers\n",
        "        self.hidden_layer = torch.nn.Linear(self.bert_hidden_dimension, 512)\n",
        "        self.group_layer1 = torch.nn.Linear(512, 64)\n",
        "        self.group_layer2 = torch.nn.Linear(512, 64)\n",
        "        self.group_layer3 = torch.nn.Linear(512, 64)\n",
        "        self.group_layer4 = torch.nn.Linear(512, 64)\n",
        "        self.group_layer5 = torch.nn.Linear(512, 64)\n",
        "        self.classifier_group1 = torch.nn.Linear(64, 1)\n",
        "        self.classifier_group2 = torch.nn.Linear(64, 1)\n",
        "        self.classifier_group3 = torch.nn.Linear(64, 1)\n",
        "        self.classifier_group4 = torch.nn.Linear(64, 1)\n",
        "        self.classifier_group5 = torch.nn.Linear(64, 1)\n",
        "        \n",
        "        # Seperate outputs for all the 20 classes\n",
        "        self.hidden_layer1 = torch.nn.Linear(64, 32)\n",
        "        self.hidden_layer2 = torch.nn.Linear(64, 32)\n",
        "        self.hidden_layer3 = torch.nn.Linear(64, 32)\n",
        "        self.hidden_layer4 = torch.nn.Linear(64, 32)\n",
        "        self.hidden_layer5 = torch.nn.Linear(64, 32)\n",
        "        self.hidden_layer6 = torch.nn.Linear(64, 32)\n",
        "        self.hidden_layer7 = torch.nn.Linear(64, 32)\n",
        "        self.hidden_layer8 = torch.nn.Linear(64, 32)\n",
        "        self.hidden_layer9 = torch.nn.Linear(64, 32)\n",
        "        self.hidden_layer10 = torch.nn.Linear(64, 32)\n",
        "        self.hidden_layer11 = torch.nn.Linear(64, 32)\n",
        "        self.hidden_layer12 = torch.nn.Linear(64, 32)\n",
        "        self.hidden_layer13 = torch.nn.Linear(64, 32)\n",
        "        self.hidden_layer14 = torch.nn.Linear(64, 32)\n",
        "        self.hidden_layer15 = torch.nn.Linear(64, 32)\n",
        "        self.hidden_layer16 = torch.nn.Linear(64, 32)\n",
        "        self.hidden_layer17 = torch.nn.Linear(64, 32)\n",
        "        self.hidden_layer18 = torch.nn.Linear(64, 32)\n",
        "        self.hidden_layer19 = torch.nn.Linear(64, 32)\n",
        "        self.hidden_layer20 = torch.nn.Linear(64, 32)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.classifier1 = torch.nn.Linear(32, 1)\n",
        "        self.classifier2 = torch.nn.Linear(32, 1)\n",
        "        self.classifier3 = torch.nn.Linear(32, 1)\n",
        "        self.classifier4 = torch.nn.Linear(32, 1)\n",
        "        self.classifier5 = torch.nn.Linear(32, 1)\n",
        "        self.classifier6 = torch.nn.Linear(32, 1)\n",
        "        self.classifier7 = torch.nn.Linear(32, 1)\n",
        "        self.classifier8 = torch.nn.Linear(32, 1)\n",
        "        self.classifier9 = torch.nn.Linear(32, 1)\n",
        "        self.classifier10 = torch.nn.Linear(32, 1)\n",
        "        self.classifier11 = torch.nn.Linear(32, 1)\n",
        "        self.classifier12 = torch.nn.Linear(32, 1)\n",
        "        self.classifier13 = torch.nn.Linear(32, 1)\n",
        "        self.classifier14 = torch.nn.Linear(32, 1)\n",
        "        self.classifier15 = torch.nn.Linear(32, 1)\n",
        "        self.classifier16 = torch.nn.Linear(32, 1)\n",
        "        self.classifier17 = torch.nn.Linear(32, 1)\n",
        "        self.classifier18 = torch.nn.Linear(32, 1)\n",
        "        self.classifier19 = torch.nn.Linear(32, 1)\n",
        "        self.classifier20 = torch.nn.Linear(32, 1)\n",
        "        \n",
        "        self.log_softmax = torch.nn.LogSoftmax(dim=2)\n",
        "\n",
        "    def encode_text(\n",
        "        self,\n",
        "        symbols: Dict\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"Encode the (batch of) sequence(s) of token symbols with an LSTM.\n",
        "            Then, get the last (non-padded) hidden state for each symbol and return that.\n",
        "\n",
        "        Args:\n",
        "            symbols (Dict): The Dict of token specifications provided by the HuggingFace tokenizer\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The final hiddens tate of the LSTM, which represents an encoding of\n",
        "                the entire sentence\n",
        "        \"\"\"\n",
        "        # First we get the contextualized embedding for each input symbol\n",
        "        # We no longer need an LSTM, since BERT encodes context and \n",
        "        # gives us a single vector describing the sequence in the form of the [CLS] token.\n",
        "        embedded = self.bert(**symbols)\n",
        "        # Get the [CLS] token using the `pooler_output` from \n",
        "        #      The BertModel output. See here: https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertModel\n",
        "        #      and check the returns for the forward method.\n",
        "        # We want to return a tensor of the form batch_size x 1 x bert_hidden_dimension\n",
        "        #raise NotImplementedError\n",
        "        \n",
        "        last_hidden_state = embedded.last_hidden_state[:,0,:]\n",
        "        hidden_shape = last_hidden_state.shape\n",
        "        return torch.reshape(last_hidden_state,(hidden_shape[0],1,hidden_shape[1]) )\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        symbols: Dict,\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"_summary_\n",
        "\n",
        "        Args:\n",
        "            symbols (Dict): The Dict of token specifications provided by the HuggingFace tokenizer\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: _description_\n",
        "        \"\"\"\n",
        "        encoded_sents = self.encode_text(symbols)\n",
        "        #Grouping\n",
        "        #Group1 - {'Achievement', 'Face', 'Power: dominance', 'Power: resources'}\n",
        "        enc = self.hidden_layer(encoded_sents)\n",
        "        group1 = self.group_layer1(enc)\n",
        "        group1 = self.relu(group1)\n",
        "        group_output1 = self.classifier_group1(group1)\n",
        "        group_output1 = torch.nn.Sigmoid()(group_output1)\n",
        "        \n",
        "        #Group2 - {'Benevolence: caring', 'Benevolence: dependability', 'Humility', 'Universalism: concern'}\n",
        "        group2 = self.group_layer2(enc)\n",
        "        group2 = self.relu(group2)\n",
        "        group_output2 = self.classifier_group2(group2)\n",
        "        group_output2 = torch.nn.Sigmoid()(group_output2)\n",
        "        \n",
        "        #Group3 - {'Stimulation', 'Tradition', 'Self-direction: action', 'Self-direction: thought'}\n",
        "        group3 = self.group_layer3(enc)\n",
        "        group3 = self.relu(group3)\n",
        "        group_output3 = self.classifier_group3(group3)\n",
        "        group_output3 = torch.nn.Sigmoid()(group_output3)\n",
        "        \n",
        "        #Group4 - {'Conformity: interpersonal', 'Conformity: rules', 'Security: personal', 'Security: societal'}\n",
        "        group4 = self.group_layer4(enc)\n",
        "        group4 = self.relu(group4)\n",
        "        group_output4 = self.classifier_group4(group4)\n",
        "        group_output4 = torch.nn.Sigmoid()(group_output4)\n",
        "        \n",
        "        #Group5 - {'Hedonism, Universalism: nature', 'Universalism: objectivity', 'Universalism: tolerance'}\n",
        "        group5 = self.group_layer5(enc)\n",
        "        group5 = self.relu(group5)\n",
        "        group_output5 = self.classifier_group5(group5)\n",
        "        group_output5 = torch.nn.Sigmoid()(group_output5)\n",
        "        \n",
        "        output1 = self.hidden_layer1(group1)\n",
        "        output1 = self.relu(output1)\n",
        "        output1 = self.classifier1(output1)\n",
        "        output1 = torch.nn.Sigmoid()(output1)\n",
        "        \n",
        "        output2 = self.hidden_layer2(group1)\n",
        "        output2 = self.relu(output2)\n",
        "        output2 = self.classifier2(output2)\n",
        "        output2 = torch.nn.Sigmoid()(output2)\n",
        "        \n",
        "        output3 = self.hidden_layer3(group1)\n",
        "        output3 = self.relu(output3)\n",
        "        output3 = self.classifier3(output3)\n",
        "        output3 = torch.nn.Sigmoid()(output3)\n",
        "        \n",
        "        output4 = self.hidden_layer4(group5)\n",
        "        output4 = self.relu(output4)\n",
        "        output4 = self.classifier4(output4)\n",
        "        output4 = torch.nn.Sigmoid()(output4)\n",
        "        \n",
        "        output5 = self.hidden_layer5(group2)\n",
        "        output5 = self.relu(output5)\n",
        "        output5 = self.classifier5(output5)\n",
        "        output5 = torch.nn.Sigmoid()(output5)\n",
        "        \n",
        "        \n",
        "        output6 = self.hidden_layer6(group2)\n",
        "        output6 = self.relu(output6)\n",
        "        output6 = self.classifier6(output6)\n",
        "        output6 = torch.nn.Sigmoid()(output6)\n",
        "        \n",
        "        \n",
        "        output7 = self.hidden_layer7(group2)\n",
        "        output7 = self.relu(output7)\n",
        "        output7 = self.classifier7(output7)\n",
        "        output7 = torch.nn.Sigmoid()(output7)\n",
        "        \n",
        "        \n",
        "        output8 = self.hidden_layer8(group2)\n",
        "        output8 = self.relu(output8)\n",
        "        output8 = self.classifier8(output8)\n",
        "        output8 = torch.nn.Sigmoid()(output8)\n",
        "        \n",
        "        output9 = self.hidden_layer9(group3)\n",
        "        output9 = self.relu(output9)\n",
        "        output9 = self.classifier9(output9)\n",
        "        output9 = torch.nn.Sigmoid()(output9)\n",
        "        \n",
        "        output10 = self.hidden_layer10(group3)\n",
        "        output10 = self.relu(output10)\n",
        "        output10 = self.classifier10(output10)\n",
        "        output10 = torch.nn.Sigmoid()(output10)\n",
        "        \n",
        "        output11 = self.hidden_layer11(group1)\n",
        "        output11 = self.relu(output11)\n",
        "        output11 = self.classifier11(output11)\n",
        "        output11 = torch.nn.Sigmoid()(output11)\n",
        "        \n",
        "        output12 = self.hidden_layer12(group3)\n",
        "        output12 = self.relu(output12)\n",
        "        output12 = self.classifier12(output12)\n",
        "        output12 = torch.nn.Sigmoid()(output12)\n",
        "        \n",
        "        output13 = self.hidden_layer13(group3)\n",
        "        output13 = self.relu(output13)\n",
        "        output13 = self.classifier13(output13)\n",
        "        output13 = torch.nn.Sigmoid()(output13)\n",
        "        \n",
        "        output14 = self.hidden_layer14(group4)\n",
        "        output14 = self.relu(output14)\n",
        "        output14 = self.classifier14(output14)\n",
        "        output14 = torch.nn.Sigmoid()(output14)\n",
        "        \n",
        "        output15 = self.hidden_layer15(group4)\n",
        "        output15 = self.relu(output15)\n",
        "        output15 = self.classifier15(output15)\n",
        "        output15 = torch.nn.Sigmoid()(output15)\n",
        "        \n",
        "        output16 = self.hidden_layer16(group4)\n",
        "        output16 = self.relu(output16)\n",
        "        output16 = self.classifier16(output16)\n",
        "        output16 = torch.nn.Sigmoid()(output16)\n",
        "        \n",
        "        output17 = self.hidden_layer17(group4)\n",
        "        output17 = self.relu(output17)\n",
        "        output17 = self.classifier17(output17)\n",
        "        output17 = torch.nn.Sigmoid()(output17)\n",
        "        \n",
        "        output18 = self.hidden_layer18(group5)\n",
        "        output18 = self.relu(output18)\n",
        "        output18 = self.classifier18(output18)\n",
        "        output18 = torch.nn.Sigmoid()(output18)\n",
        "        \n",
        "        output19 = self.hidden_layer19(group5)\n",
        "        output19 = self.relu(output19)\n",
        "        output19 = self.classifier19(output19)\n",
        "        output19 = torch.nn.Sigmoid()(output19)\n",
        "        \n",
        "        output20 = self.hidden_layer20(group5)\n",
        "        output20 = self.relu(output20)\n",
        "        output20 = self.classifier20(output20)\n",
        "        output20 = torch.nn.Sigmoid()(output20)\n",
        "        outputs = torch.cat((output1, output2, output3, output4, output5, output6, output7, output8, output9, output10, output11, output12, output13, output14, output15, output16, output17, output18, output19, output20),2)\n",
        "        group_outputs = torch.cat((group_output1, group_output2, group_output3, group_output4, group_output5),2)\n",
        "        return outputs, group_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T06:07:42.180209Z",
          "iopub.status.busy": "2022-12-13T06:07:42.179832Z",
          "iopub.status.idle": "2022-12-13T06:07:42.185016Z",
          "shell.execute_reply": "2022-12-13T06:07:42.184310Z",
          "shell.execute_reply.started": "2022-12-13T06:07:42.180184Z"
        },
        "id": "w56Kynj22y80",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def predict(model: torch.nn.Module, sents: torch.Tensor) -> List:\n",
        "    sents = sents.to(device)\n",
        "    logits = model(sents)[0]\n",
        "    res = []\n",
        "    logitslen = len(logits)\n",
        "    #print(logits[0].shape)\n",
        "    for i in range(logitslen):\n",
        "        datares = []\n",
        "        for j in range(20):\n",
        "            datares.append(logits[i][0][j] > 0.5)\n",
        "        res.append(datares)\n",
        "    return res\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:46:58.921612Z",
          "iopub.status.busy": "2022-12-13T02:46:58.921213Z",
          "iopub.status.idle": "2022-12-13T02:46:58.930015Z",
          "shell.execute_reply": "2022-12-13T02:46:58.929209Z",
          "shell.execute_reply.started": "2022-12-13T02:46:58.921586Z"
        },
        "id": "cnSswFRd3WzN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "QWXeV9E6Q-CZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T02:46:59.980689Z",
          "iopub.status.busy": "2022-12-13T02:46:59.980303Z",
          "iopub.status.idle": "2022-12-13T02:46:59.989158Z",
          "shell.execute_reply": "2022-12-13T02:46:59.988494Z",
          "shell.execute_reply.started": "2022-12-13T02:46:59.980666Z"
        },
        "id": "lVZr4mEb81_f"
      },
      "outputs": [],
      "source": [
        "def f1Score_multiLabel(preds, labels):\n",
        "    nLabels = 20\n",
        "    relevants = [0]*20\n",
        "    positives = [0]*20\n",
        "    truePositives = [0]*20\n",
        "    correct = [0]*20\n",
        "    for i in range(len(preds)):\n",
        "        for j in range(nLabels):\n",
        "            if(preds[i][j]==1):\n",
        "                positives[j] += 1\n",
        "                if(labels[i][j]==1):\n",
        "                    truePositives[j] += 1\n",
        "    for i in range(len(preds)):\n",
        "        for j in range(nLabels):\n",
        "            if(preds[i][j]==labels[i][j]):\n",
        "                correct[j] += 1\n",
        "    \n",
        "    for i in range(len(labels)):\n",
        "        for j in range(nLabels):\n",
        "            if(labels[i][j]==1):\n",
        "                relevants[j] += 1\n",
        "    \n",
        "    precisions = []*nLabels\n",
        "    recalls = []*nLabels\n",
        "    f1Scores = []*nLabels\n",
        "    accuracies = []*nLabels\n",
        "    \n",
        "    #print(truePositives, positives, relevants)\n",
        "    for i in range(nLabels):\n",
        "        precision =0\n",
        "        recall = 0\n",
        "        f1 = 0    \n",
        "        if(positives[i]>0):\n",
        "            precision = truePositives[i]/positives[i]\n",
        "        precisions.append(precision)\n",
        "        if(relevants[i]>0):\n",
        "            recall = truePositives[i]/relevants[i]\n",
        "        recalls.append(recall)\n",
        "        #print(precision,recall,i)\n",
        "        if(precision>0 and recall>0):\n",
        "            f1 = 2 * precision * recall / (precision + recall)\n",
        "        f1Scores.append(f1)\n",
        "        accuracies.append(correct[i]/len(preds))\n",
        "    precision_mean = np.mean(precisions)\n",
        "    recall_mean = np.mean(recalls)\n",
        "    f1_mean = np.mean(f1Scores)\n",
        "    accuracy = np.mean(accuracies)\n",
        "    return f1_mean, precision_mean, recall_mean, accuracy, f1Scores, precisions, recalls, accuracies\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OQTKS0YAXGyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "GAl6rHerQ4FO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyE6cJhM3i9M"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from torchmetrics.classification import MultilabelHammingDistance\n",
        "def training_loop(\n",
        "    num_epochs,\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    dev_sents,\n",
        "    dev_labels,\n",
        "    optimizer,\n",
        "    model,\n",
        "    best_f1,\n",
        "):\n",
        "    print(\"Training...\")\n",
        "    all_f1 = []\n",
        "    all_P = []\n",
        "    all_R = []\n",
        "    all_L = []\n",
        "    all_CELoss = []\n",
        "    all_HMLoss = []\n",
        "    all_acc = []\n",
        "    loss_func = torch.nn.CrossEntropyLoss()\n",
        "    hammingLoss20 = MultilabelHammingDistance(num_labels=20)\n",
        "    batches = list(zip(train_features, train_labels))\n",
        "    random.shuffle(batches)\n",
        "    for i in range(num_epochs):\n",
        "        losses = []\n",
        "        for features, labels in tqdm(batches):\n",
        "            # Empty the dynamic computation graph\n",
        "            features = features.to(device)\n",
        "            labels = labels.float()\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(features)\n",
        "            local_loss = loss_func(preds[0].squeeze(1),labels[:,:20])\n",
        "            group_loss = loss_func(preds[1].squeeze(1),labels[:,20:25])\n",
        "            loss = local_loss + 4*group_loss\n",
        "            # Backpropogate the loss through our model\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            losses.append(loss.item())\n",
        "        \n",
        "        print(f\"epoch {i}, loss: {np.sum(losses)/len(losses)}\")\n",
        "        # Estimate the f1 score for the development set\n",
        "        print(\"Evaluating dev...\")\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        for sents, labels in tqdm(zip(dev_sents, dev_labels), total=len(dev_sents)):\n",
        "            sents = sents.to(device)\n",
        "            pred = predict(model, sents)\n",
        "            all_preds.extend(pred)\n",
        "            all_labels.extend(list(labels))\n",
        "        # #print(range(len(set(train_labels))))\n",
        "\n",
        "        dev_f1, dev_P, dev_R, dev_acc, dev_all_f1, dev_all_P, dev_all_R, dev_all_acc = f1Score_multiLabel(all_preds, all_labels)\n",
        "        print(f\"Dev F1 {dev_f1},  Dev Precision {dev_P}, Dev Recall {dev_R}, Dev Accuracy {dev_acc}\")\n",
        "        print(dev_all_P[2:4],dev_all_P[12:14])\n",
        "        if dev_f1 > best_f1:\n",
        "            torch.save(model, 'best-f1.pt')\n",
        "            best_f1 = dev_f1\n",
        "            print(\"Best F1 \", best_f1)\n",
        "        all_f1.append(dev_all_f1)\n",
        "        all_P.append(dev_all_P)\n",
        "        all_R.append(dev_all_R)\n",
        "        all_L.append(losses)\n",
        "        all_acc.append(dev_all_acc)\n",
        "       \n",
        "    # Return the trained model\n",
        "    with open(\"all_f1_base.csv\", 'ab') as abc:\n",
        "        np.savetxt(abc, \n",
        "               all_f1,\n",
        "               delimiter =\", \", \n",
        "               fmt ='%s')\n",
        "    with open(\"all_P_base.csv\", 'ab') as abc:\n",
        "        np.savetxt(abc, \n",
        "               all_P,\n",
        "               delimiter =\", \", \n",
        "               fmt ='%s')\n",
        "    with open(\"all_R_base.csv\", 'ab') as abc:\n",
        "        np.savetxt(abc, \n",
        "               all_R,\n",
        "               delimiter =\", \", \n",
        "               fmt ='%s')\n",
        "    with open(\"all_acc_base.csv\", 'ab') as abc:\n",
        "        np.savetxt(abc, \n",
        "               all_acc,\n",
        "               delimiter =\", \", \n",
        "               fmt ='%s')\n",
        "    with open(\"all_L_base.csv\", 'ab') as abc:\n",
        "        np.savetxt(abc, \n",
        "               all_L,\n",
        "               delimiter =\", \", \n",
        "               fmt ='%s')\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liqb8oDn4fNx"
      },
      "outputs": [],
      "source": [
        "from transformers.optimization import get_linear_schedule_with_warmup\n",
        "epochs = 300\n",
        "epoch_warmup = 40\n",
        "best_f1 = 0\n",
        "# TODO: Find a good learning rate\n",
        "LR = 1e-4\n",
        "\n",
        "possible_labels = 20\n",
        "model = GroupedClassifier(output_size=possible_labels, hidden_size=512)\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), LR)\n",
        "#scheduler = get_linear_schedule_with_warmup(optimizer, epoch_warmup,epochs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0ThGzo64w64",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#epochs=50\n",
        "#LR=1e-4\n",
        "optimizer = torch.optim.AdamW(model.parameters(), LR)\n",
        "model =training_loop(\n",
        "    epochs,\n",
        "    train_input_batches,\n",
        "    train_label_batches,\n",
        "    val_input_batches,\n",
        "    val_label_batches,\n",
        "    optimizer,\n",
        "    model,\n",
        "    best_f1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jm32MKhGXqdy"
      },
      "outputs": [],
      "source": [
        "model = torch.load('best-f1.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation Set"
      ],
      "metadata": {
        "id": "ZGObmC0jQ0RT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluating dev...\")\n",
        "all_preds_val = []\n",
        "all_labels = []\n",
        "for sents, labels in tqdm(zip(val_input_batches, val_label_batches), total=len(val_input_batches)):\n",
        "    sents = sents.to(device)\n",
        "    pred = predict(model, sents)\n",
        "    all_preds_val.extend(pred)\n",
        "    all_labels.extend(list(labels))\n",
        "# #print(range(len(set(train_labels))))\n",
        "\n",
        "dev_f1, dev_P, dev_R, dev_acc, dev_all_f1, dev_all_P, dev_all_R, dev_all_acc = f1Score_multiLabel(all_preds_val, all_labels)\n",
        "print(f\"Dev F1 {dev_f1},  Dev Precision {dev_P}, Dev Recall {dev_R}, Dev Accuracy {dev_acc}\")\n"
      ],
      "metadata": {
        "id": "EoPWfDWH9Idv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_preds1_val = []\n",
        "for row in all_preds_val:\n",
        "    row1 = []\n",
        "    for item in row:\n",
        "        val = item.cpu().numpy()\n",
        "        if val == True:\n",
        "            row1.append(1)\n",
        "        else:\n",
        "            row1.append(0)\n",
        "    all_preds1_val.append(row1)"
      ],
      "metadata": {
        "id": "xb2wKaBt9Vfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_ids = ['Self-direction: thought', 'Self-direction: action', 'Stimulation',\n",
        "       'Hedonism', 'Achievement', 'Power: dominance', 'Power: resources',\n",
        "       'Face', 'Security: personal', 'Security: societal', 'Tradition',\n",
        "       'Conformity: rules', 'Conformity: interpersonal', 'Humility',\n",
        "       'Benevolence: caring', 'Benevolence: dependability',\n",
        "       'Universalism: concern', 'Universalism: nature',\n",
        "       'Universalism: tolerance', 'Universalism: objectivity']"
      ],
      "metadata": {
        "id": "7oIEZWbR9b_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_preds_df_val = pd.DataFrame(all_preds1_val, columns=label_ids)\n",
        "write_tsv_dataframe('preds-val-GroupingHybrid.tsv', all_preds_df_val)"
      ],
      "metadata": {
        "id": "K6TKPt5L9heY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Set "
      ],
      "metadata": {
        "id": "MNJ1O-rJQvW1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bIOWNDdXqdy"
      },
      "outputs": [],
      "source": [
        "def generate_inputs(dataset, datatype):\n",
        "    \"\"\"\n",
        "    TODO: group all premises and corresponding hypotheses and labels of the datapoints\n",
        "    a datapoint as seen earlier is a dict of premis, hypothesis and label\n",
        "    \"\"\"\n",
        "    #raise NotImplementedError\n",
        "    premise=[]\n",
        "    conclusion=[]\n",
        "    stance=[]\n",
        "    \n",
        "    label=[]\n",
        "    \n",
        "    n = len(dataset['Argument ID'])\n",
        "    arguments = []\n",
        "    print(n)\n",
        "    for i in range(n):\n",
        "        if dataset['Usage'][i]==datatype:\n",
        "          premise.append(dataset['Premise'][i])\n",
        "          conclusion.append(dataset['Conclusion'][i])\n",
        "          stance.append(dataset['Stance'][i])\n",
        "          arguments.append(dataset['Argument ID'][i])\n",
        "    \n",
        "    return premise, conclusion, stance, arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "5aWA-q72Xqdy"
      },
      "outputs": [],
      "source": [
        "test_argument_filepath = os.path.join(data_dir, 'arguments-test.tsv')\n",
        "df_arguments_test = load_arguments_from_tsv(test_argument_filepath, default_usage='test')\n",
        "test_premises, test_conclusion, test_stance, test_arguments = generate_inputs(df_arguments_test, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRhVZ_9CXqdz"
      },
      "outputs": [],
      "source": [
        "print(\"Evaluating test...\")\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "batch_size=64\n",
        "tokenizer = BatchTokenizer()\n",
        "\n",
        "test_input_batches = [b for b in chunk_multi(test_premises, test_conclusion, test_stance, batch_size)]\n",
        "# Tokenize + encode\n",
        "test_input_batches = [tokenizer(*batch) for batch in test_input_batches]\n",
        "\n",
        "\n",
        "#test_label_batches = [b for b in chunk(test_labels, batch_size)]\n",
        "#test_label_batches = [encode_labels(batch) for batch in test_label_batches]\n",
        "for sents in tqdm(test_input_batches):\n",
        "    pred = predict(model, sents)\n",
        "    all_preds.extend(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhhjYTp_Xqdz"
      },
      "outputs": [],
      "source": [
        "all_preds1 = []\n",
        "for row in all_preds:\n",
        "    row1 = []\n",
        "    for item in row:\n",
        "        val = item.cpu().numpy()\n",
        "        if val == True:\n",
        "            row1.append(1)\n",
        "        else:\n",
        "            row1.append(0)\n",
        "    all_preds1.append(row1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Egy9RdZdXqdz"
      },
      "outputs": [],
      "source": [
        "label_ids = ['Self-direction: thought', 'Self-direction: action', 'Stimulation',\n",
        "       'Hedonism', 'Achievement', 'Power: dominance', 'Power: resources',\n",
        "       'Face', 'Security: personal', 'Security: societal', 'Tradition',\n",
        "       'Conformity: rules', 'Conformity: interpersonal', 'Humility',\n",
        "       'Benevolence: caring', 'Benevolence: dependability',\n",
        "       'Universalism: concern', 'Universalism: nature',\n",
        "       'Universalism: tolerance', 'Universalism: objectivity']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIWDt2LOXqdz"
      },
      "outputs": [],
      "source": [
        "all_preds_df = pd.DataFrame(all_preds1, columns=label_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMSUfJojXqd0"
      },
      "outputs": [],
      "source": [
        "all_preds_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8dMpWwSXqd0"
      },
      "outputs": [],
      "source": [
        "write_tsv_dataframe('preds-test-GroupingHybrid.tsv', all_preds_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWJzRo0vXqd0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}